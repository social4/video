[🌐 𝖢𝖫𝖨𝖢𝖪 𝖧𝖤𝖱𝖤 🟢==►► 𝖶𝖠𝖳𝖢𝖧 𝖭𝖮𝖶](https://3-tanei-pinik.blogspot.com/2025/02/viral-video.html)

[🔴 𝖢𝖫𝖨𝖢𝖪 𝖧𝖤𝖱𝖤 🌐==►► 𝖣𝗈𝗐𝗇𝗅𝗈𝖺𝖽 𝖭𝗈𝗐](https://3-tanei-pinik.blogspot.com/2025/02/viral-video.html)

[🌐 𝖢𝖫𝖨𝖢𝖪 𝖧𝖤𝖱𝖤 🟢==►► 𝖶𝖠𝖳𝖢𝖧 𝖭𝖮𝖶](https://3-tanei-pinik.blogspot.com/2025/02/viral-video.html)

[![Image](https://github.com/user-attachments/assets/ff3b7bd4-415c-4ca3-a6c8-b1f096193c29)](https://3-tanei-pinik.blogspot.com/2025/02/viral-video.html)



These trends are making the spread of child sex abuse worse, according to a child safety advocate


Ava says that one day she met a boy who she thought liked her.

He asked her to do a video chat. She agreed. But she did not agree for him to record the chat, which became sexual in nature, nor did she consent to him to then share the video.

The video spread like wildfire.

“I thought that this boy must really like me, but as I later found out this was very premeditated,” said Ava, who was 14 at the time and used a pseudonym to protect her identity. Ava shared her story through a video on the Canadian Centre for Child Protection’s website.

“He knew what he was doing, he recorded the video call and sent it to a friend who sent it to another friend who sent it to another friend and eventually it got sent to everyone on this website and then it was shared to other websites, porn sites, random pages from different countries,” she said.

She soon would spend much of her free time after school on her laptop.

The child sex abuse survivor says she was filing requests for websites to take down the sexual exploitative videos of her. At the same time, she was receiving messages from “random creeps.”

“It becomes the only thing you can think about, the only thing you care about,” Ava said. “I had no time for anything else because I very quickly realized that at the time if I wasn’t going to do anything, no one would do anything.”

She said the nightmare of “constantly retraumatizing” herself searching for the video ended when she connected with the Canadian Centre for Child Protection, which developed the Project Arachnid digital tool in 2017.

For the past eight years, the Winnipeg-based charity has deployed “web crawlers” to search for publicly available child sexual abuse images and video on both the normal internet and the dark web. The dark web is where online activity is kept anonymous. The charity also gets tips from the public about secret groups, such as those on Facebook or WhatsApp, where the content may be shared.

“It’s this perverse game of whack-a-mole that happens across the internet,” Jacques Marcoux, director of research and analytics with the Canadian Centre for Child Protection (C3P) in Winnipeg, said in a video interview with CTVNews.ca. “So what we see is that a lot of service providers who don’t want to have to deal with that problem will purposefully design their site in such a way that it’s hard to report content to them or that there’s no abuse contact email.”

Marcoux says the charity uses its tool to find any “highly sexualized images” of children, even those who are still wearing clothing, that may be considered “lawful but awful.”

Since Project Arachnid launched, the charity says that it has issued a total of nearly 50 million notices for companies to take down child sex abuse material. The removal notices targeted more than 1,500 online operators, from well-known social media companies to firms that host content, from more than 100 countries. Each day alone, it says it sends between 2,000 to 15,000 notices to companies around the world.

When asked about the concerns regarding child sex abuse material found on social media and other platforms, a Meta spokesperson said it has made efforts to combat the problem. The spokesperson said Meta shares information about the illicit activity with other tech companies and reports all suspected incidents to the National Center for Missing and Exploited Children, which works with Canadian law enforcement.

“Child exploitation is a horrific crime,” the spokesperson wrote in an email to CTVNews.ca. “We’ve spent years developing policies and tools to fight it, including sophisticated technology to find and remove child exploitation content.”

Trends with online predators
Artificial intelligence and other tech tools are making it harder to crack down on the growing problem of child sex abuse material online, Marcoux said.

AI has made it easy for individuals to create their own child sex abuse material, such as deepfakes and face swaps that alter and manipulate content, Marcoux said.

Offenders will take images of a child in their community and steal the pictures from an Instagram account or Facebook, for example, then train the AI technology to generate the abusive content, Marcoux said.

“There have been cases you can find in Canada where that has happened in high schools where some boys, for example, created AI-generated, intimate images of girls in their school,” Marcoux said.

To add to that, he said tools that allow anonymity are more available, allowing offenders to hide their IP address identifying the device and geolocation, which makes it harder for police to investigate cases.

“So this is the wide use of VPNs, the increased use of encrypted services where the companies can no longer monitor what’s happening, and then also just the use of the dark web,” he said.

The dark web allows people to do “just about anything with complete impunity,” he said.

Challenges with compliance
The Canadian charity advocating for sexually-exploited children says it gets hundreds of calls each week from youth who need help removing the harmful content online. In some cases, Marcoux said the youth are being sextorted, or threatened into sending explicit content or paying money to avoid that content from being shared. He said the charity doesn’t investigate offenders and instead mainly notifies companies to ask them to take down the harmful images. The charity also helps victims get the content removed and refers them to law enforcement and other resources.

After the Project Arachnid digital tool finds child abuse material, the Canadian Centre for Child Protection issues takedown notices to companies that host the content. For about 70 per cent of cases, the companies remove the content within about 48 hours, Marcoux said, which he said is still “not fast enough.”

Millions of images are being reshared when 30 per cent of companies that receive the takedown notices don’t remove the images, or take even longer to do so, he added.

“Companies will generally comply when we tell them about it, but the problem is that they don’t then take steps to prevent that from happening in the first place,” Marcoux said. “And that is the reason why we as an organization have been pushing Canada’s government and other governments to move forward with online safety legislation to ensure that these companies have actual legal requirements.”

He said Bill C-63, or the Online Harms Act, could have forced platforms to remove content that “sexually victimizes” a child or remove intimate images posted without consent, but it recently died because of prorogation.

Another problem is the charity will notify the same company multiple times about an image showing up on its platform over and over again, when the company should have blocked the image from reappearing in the first place, he said.

It’s illegal for individuals to access, possess, make and distribute child sexual abuse material in Canada and most countries, he said. In Canada, it’s a crime to visually depict someone under 18 years old engaged in explicit sexual activity, including using AI, Photoshop or other tools.

Online service providers, such as social media services, video upload sites and file-hosting cloud storage platforms, generally aren’t viewed as being liable for the content their users upload, Marcoux said.

But when they become aware of the harmful content, their legal obligations generally kick in, including in Canada and the U.S. where they must report it to law enforcement authorities, he said.

“So companies don’t have obligations to try and find it, or to try and root out the problem, but they have obligations when someone flags it to them or they become aware of it,” he said. “And from a policy perspective, we think that’s problematic because it can often encourage companies to not have to be proactive about any of this.”

Even with the proliferation of the harmful content online, Ava encourages survivors to reach out for help and know there is a solution.

“The shame makes you feel like you’re the one who did something wrong, but that’s not true,” she said. “There are people who care, there are people who will do tireless work to help. The light is there and you will reach it -- you just have to keep going.”
